{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "df_technology = pd.read_csv(\"data/technology_news.csv\", encoding='utf-8')\n",
    "df_technology = df_technology.dropna()\n",
    "\n",
    "df_car = pd.read_csv(\"data/car_news.csv\", encoding='utf-8')\n",
    "df_car = df_car.dropna()\n",
    "\n",
    "df_entertainment = pd.read_csv(\"data/entertainment_news.csv\", encoding='utf-8')\n",
    "df_entertainment = df_entertainment.dropna()\n",
    "\n",
    "df_military = pd.read_csv(\"data/military_news.csv\", encoding='utf-8')\n",
    "df_military = df_military.dropna()\n",
    "\n",
    "df_sports = pd.read_csv(\"data/sports_news.csv\", encoding='utf-8')\n",
    "df_sports = df_sports.dropna()\n",
    "\n",
    "technology = df_technology.content.values.tolist()[1000:21000]\n",
    "car = df_car.content.values.tolist()[1000:21000]\n",
    "entertainment = df_entertainment.content.values.tolist()[:20000]\n",
    "military = df_military.content.values.tolist()[:20000]\n",
    "sports = df_sports.content.values.tolist()[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=pd.read_csv(\"data/stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stopwords=stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\LL\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.804 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(content_lines, sentences, category):\n",
    "    for line in content_lines:\n",
    "            segs=jieba.lcut(line)\n",
    "            segs = list(filter(lambda x:len(x)>1, segs))\n",
    "            segs = list(filter(lambda x:x not in stopwords, segs))\n",
    "            sentences.append((\" \".join(segs), category))\n",
    "            data.append(segs)\n",
    "\n",
    "#生成训练数据\n",
    "sentences = []\n",
    "data = []\n",
    "\n",
    "#preprocess_text(technology, sentences, 'technology')\n",
    "preprocess_text(car, sentences, 'car')\n",
    "#preprocess_text(entertainment, sentences, 'entertainment')\n",
    "preprocess_text(military, sentences, 'military')\n",
    "#preprocess_text(sports, sentences, 'sports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上面data表示的是标准的Word2Vec的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "train_data, test_data, train_target, test_target = train_test_split(x, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_dic = {'car':1, 'military':2}\n",
    "train_target = list(map(lambda x:cate_dic[x], train_target))\n",
    "test_target = list(map(lambda x:cate_dic[x], test_target))\n",
    "y_train = pd.Series(train_target)\n",
    "y_test = pd.Series(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先利用gensim的word2Vec得到词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec  #导入Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设定参数\n",
    "size = 50\n",
    "window = 5\n",
    "min_count = 4\n",
    "worker = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(data, size=size, window=window, min_count=min_count, workers=worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('直播', 0.984207034111023),\n",
       " ('在线', 0.9761182069778442),\n",
       " ('宝驾', 0.9708111882209778),\n",
       " ('绿狗', 0.9697870016098022),\n",
       " ('友友', 0.9652999639511108),\n",
       " ('曹操', 0.9648972749710083),\n",
       " ('网约', 0.9624991416931152),\n",
       " ('许可证', 0.9624050259590149),\n",
       " ('涉密', 0.9596567153930664),\n",
       " ('咨询', 0.958770751953125)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('上线')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  得到CNN的输入向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 说明，对于每天的新闻，我们会考虑前256个单词。不够的我们用[000000]补上\n",
    "# vec_size 指的是我们本身vector的size\n",
    "def transform_to_matrix(x, padding_size=50, vec_size=50):\n",
    "    res = []\n",
    "    for sen in x:\n",
    "        sen = sen.split()  #这里中英文是不一样的\n",
    "        matrix = []\n",
    "        for i in range(padding_size):\n",
    "            try:\n",
    "                matrix.append(model[sen[i]].tolist())\n",
    "            except:\n",
    "                # 这里有两种except情况，\n",
    "                # 1. 这个单词找不到\n",
    "                # 2. sen没那么长\n",
    "                # 不管哪种情况，我们直接贴上全是0的vec\n",
    "                matrix.append([0] * vec_size)\n",
    "        res.append(matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = transform_to_matrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = transform_to_matrix(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20696, 50, 50)\n",
      "(6899, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "# 搞成np的数组，便于处理\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "# 看看数组的大小\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20696, 50, 50, 1)\n",
      "(6899, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_x, test_x\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "# set parameters:\n",
    "batch_size = 32\n",
    "n_filter = 16\n",
    "filter_length = 3\n",
    "nb_epoch = 5\n",
    "n_pool = 2\n",
    "\n",
    "# 新建一个sequential的模型\n",
    "model = Sequential()\n",
    "model.add(Conv2D(n_filter,(filter_length,filter_length),\n",
    "                        input_shape=(50, 50, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(n_filter,(filter_length,filter_length)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# 后面接上一个ANN\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "# compile模型\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 8096/20696 [==========>...................] - ETA: 50s - loss: 0.6047 - acc: 0.3953"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
