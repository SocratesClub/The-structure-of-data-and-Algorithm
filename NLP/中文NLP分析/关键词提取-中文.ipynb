{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba.analyse as analyse\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于tf-idf的关键词抽取 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=pd.read_csv(\"data/stopwords.txt\",index_col=False,quoting=3,names=['stopword'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/car_news.csv', encoding='utf-8')  #中文记得用utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "lines=df.content.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汽车 2016\n"
     ]
    }
   ],
   "source": [
    "content = \" \".join(lines)\n",
    "print(\" \".join(analyse.extract_tags(content, topK=2, withWeight=False, allowPOS=())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于TextRank的关键词抽取 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method textrank in module jieba.analyse.textrank:\n",
      "\n",
      "textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'), withFlag=False) method of jieba.analyse.textrank.TextRank instance\n",
      "    Extract keywords from sentence using TextRank algorithm.\n",
      "    Parameter:\n",
      "        - topK: return how many top keywords. `None` for all possible words.\n",
      "        - withWeight: if True, return a list of (word, weight);\n",
      "                      if False, return a list of words.\n",
      "        - allowPOS: the allowed POS list eg. ['ns', 'n', 'vn', 'v'].\n",
      "                    if the POS of w is not in this list, it will be filtered.\n",
      "        - withFlag: if True, return a list of pair(word, weight) like posseg.cut\n",
      "                    if False, return a list of words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(analyse.textrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汽车  中国  市场  新能源  车辆  品牌  技术  发展  企业  产品  车型  服务  消费者  公司  用户  进行  系统  设计  平台  驾驶\n"
     ]
    }
   ],
   "source": [
    "print(\"  \".join(analyse.textrank(content, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用sklearn做tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.','This is the second second document.','And the third one.','Is this the first document?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_feature_names in module sklearn.feature_extraction.text:\n",
      "\n",
      "get_feature_names() method of sklearn.feature_extraction.text.TfidfVectorizer instance\n",
      "    Array mapping from feature integer indices to feature name\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vectorizer.get_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.43877674,  0.54197657,  0.43877674,  0.        ,\n",
       "         0.        ,  0.35872874,  0.        ,  0.43877674],\n",
       "       [ 0.        ,  0.27230147,  0.        ,  0.27230147,  0.        ,\n",
       "         0.85322574,  0.22262429,  0.        ,  0.27230147],\n",
       "       [ 0.55280532,  0.        ,  0.        ,  0.        ,  0.55280532,\n",
       "         0.        ,  0.28847675,  0.55280532,  0.        ],\n",
       "       [ 0.        ,  0.43877674,  0.54197657,  0.43877674,  0.        ,\n",
       "         0.        ,  0.35872874,  0.        ,  0.43877674]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec来做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(stopwords['stopword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in lines:\n",
    "    buff_1 = [w for w in list(jieba.cut(line)) if w not in stopwords]\n",
    "    buff_2 = [w for w in buff_1 if len(w) > 1]\n",
    "    data.append(buff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['本报',\n",
       " '济南',\n",
       " '日电',\n",
       " '潘俊强',\n",
       " '日前',\n",
       " '备受',\n",
       " '关注',\n",
       " '济南',\n",
       " '专车',\n",
       " '一审',\n",
       " '宣判',\n",
       " '济南市',\n",
       " '市中区',\n",
       " '人民法院',\n",
       " '济南',\n",
       " '市民',\n",
       " '陈超诉',\n",
       " '济南市',\n",
       " '城市',\n",
       " '公共',\n",
       " '客运',\n",
       " '管理',\n",
       " '服务中心',\n",
       " '行政处罚',\n",
       " '一案',\n",
       " '作出',\n",
       " '一审',\n",
       " '宣判',\n",
       " '判决',\n",
       " '撤销',\n",
       " '济南市',\n",
       " '客管',\n",
       " '中心',\n",
       " '专车',\n",
       " '司机',\n",
       " '陈超',\n",
       " '行政处罚']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设定词向量训练的参数\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 5   # Minimum word count\n",
    "num_workers = 1       # Number of threads to run in parallel\n",
    "context = 5          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "print('Training model...')\n",
    "model = Word2Vec(data, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('一汽', 0.9911147356033325),\n",
       " ('奥迪', 0.9842259287834167),\n",
       " ('上汽', 0.9678931832313538),\n",
       " ('广汽', 0.9588107466697693),\n",
       " ('旗下', 0.9486117362976074),\n",
       " ('通用汽车', 0.9350533485412598),\n",
       " ('福特', 0.9346243143081665),\n",
       " ('吉利', 0.9339005947113037),\n",
       " ('丰田', 0.9322910308837891),\n",
       " ('大通', 0.9235988259315491)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"大众\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA主题模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=pd.read_csv(\"data/stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stopwords=stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/car_news.csv\", encoding='utf-8')\n",
    "df = df.dropna()\n",
    "lines=df.content.values.tolist()\n",
    "\n",
    "sentences=[]\n",
    "for line in lines:\n",
    "    try:\n",
    "        segs=jieba.lcut(line)\n",
    "        segs = list(filter(lambda x:len(x)>1, segs))\n",
    "        segs = list(filter(lambda x:x not in stopwords, segs))\n",
    "        sentences.append(segs)\n",
    "    except Exception:\n",
    "        print(line)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = data  #这里为什么用上面的算出来是空集呢？用上上面的data就正确了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编者按\n",
      "新年伊始\n",
      "一批\n",
      "汽车\n",
      "新政\n",
      "如期而至\n",
      "展望\n",
      "2017\n",
      "中国\n",
      "汽车\n",
      "市场\n",
      "汽车\n",
      "新政\n",
      "无疑\n",
      "汽车\n",
      "市场\n",
      "格局\n",
      "产业\n",
      "结构调整\n",
      "忽视\n",
      "导向\n",
      "作用\n",
      "影响\n",
      "消费者\n",
      "日常\n",
      "汽车\n",
      "生活\n"
     ]
    }
   ],
   "source": [
    "for word in sentences[5]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(sentences)\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 2),\n",
       " (10, 2),\n",
       " (20, 1),\n",
       " (24, 1),\n",
       " (25, 2),\n",
       " (26, 2),\n",
       " (28, 2),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015*\"汽车\" + 0.012*\"品牌\" + 0.012*\"中国\" + 0.010*\"车型\" + 0.009*\"产品\" + 0.009*\"SUV\" + 0.007*\"系统\" + 0.007*\"市场\"\n",
      "0.027*\"中国\" + 0.021*\"汽车\" + 0.016*\"召回\" + 0.010*\"进口\" + 0.009*\"宝马\" + 0.008*\"品牌\" + 0.008*\"碳纤维\" + 0.008*\"指数\"\n",
      "0.024*\"汽车\" + 0.016*\"品牌\" + 0.012*\"中国\" + 0.011*\"上汽\" + 0.009*\"市场\" + 0.009*\"福特\" + 0.008*\"中新网\" + 0.007*\"日电\"\n",
      "0.026*\"设计\" + 0.010*\"全新\" + 0.010*\"动力\" + 0.009*\"系统\" + 0.008*\"车身\" + 0.008*\"车型\" + 0.007*\"采用\" + 0.007*\"性能\"\n",
      "0.010*\"活动\" + 0.010*\"停车\" + 0.008*\"租赁\" + 0.008*\"项目\" + 0.008*\"停车位\" + 0.007*\"汽车\" + 0.006*\"亿元\" + 0.006*\"全国\"\n",
      "0.027*\"奥迪\" + 0.017*\"经销商\" + 0.016*\"销售\" + 0.016*\"汽车\" + 0.010*\"万元\" + 0.010*\"市场\" + 0.010*\"公司\" + 0.009*\"优惠\"\n",
      "0.012*\"空间\" + 0.009*\"电池\" + 0.009*\"补贴\" + 0.007*\"充电\" + 0.007*\"速度\" + 0.007*\"车型\" + 0.007*\"带来\" + 0.006*\"挑战\"\n",
      "0.075*\"汽车\" + 0.019*\"发展\" + 0.016*\"中国\" + 0.016*\"企业\" + 0.015*\"市场\" + 0.012*\"新能源\" + 0.010*\"全球\" + 0.009*\"技术\"\n",
      "0.014*\"汽车\" + 0.010*\"政策\" + 0.010*\"相关\" + 0.008*\"车辆\" + 0.008*\"国家\" + 0.008*\"建设\" + 0.007*\"解决方案\" + 0.006*\"机动车\"\n",
      "0.026*\"服务\" + 0.022*\"网约车\" + 0.014*\"经营\" + 0.011*\"出租汽车\" + 0.011*\"平台\" + 0.010*\"车辆\" + 0.010*\"充电\" + 0.009*\"提供\"\n",
      "0.021*\"市场\" + 0.017*\"中国\" + 0.015*\"一汽\" + 0.015*\"品牌\" + 0.009*\"超过\" + 0.009*\"广汽\" + 0.008*\"一季度\" + 0.008*\"增长\"\n",
      "0.020*\"司机\" + 0.014*\"出租车\" + 0.012*\"出行\" + 0.011*\"驾驶员\" + 0.009*\"碰撞\" + 0.009*\"车辆\" + 0.007*\"滴滴\" + 0.007*\"网约车\"\n",
      "0.036*\"万辆\" + 0.036*\"销量\" + 0.032*\"增长\" + 0.032*\"同比\" + 0.015*\"月份\" + 0.014*\"销售\" + 0.014*\"乘用车\" + 0.012*\"下降\"\n",
      "0.040*\"二手车\" + 0.016*\"用户\" + 0.016*\"消费者\" + 0.013*\"服务\" + 0.013*\"平台\" + 0.012*\"瓜子\" + 0.012*\"品牌\" + 0.011*\"行业\"\n",
      "0.023*\"易到\" + 0.010*\"驾驶\" + 0.009*\"车辆\" + 0.008*\"功能\" + 0.007*\"检测\" + 0.007*\"汽车\" + 0.006*\"系统\" + 0.006*\"车主\"\n",
      "0.019*\"汽车\" + 0.016*\"发动机\" + 0.015*\"动力\" + 0.010*\"技术\" + 0.009*\"电动\" + 0.009*\"品牌\" + 0.008*\"混合\" + 0.008*\"模式\"\n",
      "0.015*\"车辆\" + 0.011*\"维修\" + 0.008*\"汽车\" + 0.007*\"经销商\" + 0.005*\"拍卖\" + 0.005*\"雷诺\" + 0.004*\"A3\" + 0.004*\"市场\"\n",
      "0.027*\"汽车\" + 0.010*\"租车\" + 0.010*\"用车\" + 0.009*\"北京\" + 0.009*\"城市\" + 0.009*\"共享\" + 0.008*\"车用\" + 0.008*\"有限公司\"\n",
      "0.028*\"驾驶\" + 0.021*\"车展\" + 0.020*\"智能\" + 0.019*\"汽车\" + 0.019*\"自动\" + 0.015*\"车型\" + 0.012*\"技术\" + 0.010*\"科技\"\n",
      "0.019*\"新能源\" + 0.013*\"汽车\" + 0.012*\"里程\" + 0.012*\"技术\" + 0.011*\"车辆\" + 0.010*\"续航\" + 0.009*\"公里\" + 0.007*\"产能\"\n"
     ]
    }
   ],
   "source": [
    "for topic in lda.print_topics(num_topics=20, num_words=8):\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
